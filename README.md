# ğŸ“Š Telecom X â€“ Parte 2: PredicciÃ³n de CancelaciÃ³n (Churn)
## ğŸ“Œ PropÃ³sito del Proyecto
Este proyecto corresponde a la **segunda fase del desafÃ­o Telecom X**. Tras el anÃ¡lisis exploratorio realizado en la Parte 1, aquÃ­ se desarrolla un **pipeline de Machine Learning** cuyo objetivo principal es **predecir la cancelaciÃ³n de clientes (churn)** a partir de variables relevantes. 

El propÃ³sito central es anticipar quÃ© clientes tienen mayor probabilidad de cancelar su servicio, para que la empresa pueda diseÃ±ar estrategias de retenciÃ³n efectivas.

---

## ğŸ“‚ Estructura del Proyecto
```
ğŸ“¦ telecomx-churn-part2
â”œâ”€â”€ Challenge_TelecomX_Parte2_VF.ipynb   # Notebook principal con el pipeline de ML
â”œâ”€â”€ data/                                # Carpeta con datasets crudos y tratados en CSV
â”œâ”€â”€ visualizaciones/                     # (opcional) grÃ¡ficos generados durante el anÃ¡lisis
â”œâ”€â”€ modelos/                             # (opcional) modelos serializados .pkl/.joblib
â””â”€â”€ README.md                            # Este archivo
```

---

## ğŸ”„ PreparaciÃ³n de Datos
1. **ClasificaciÃ³n de variables:**
   - **NumÃ©ricas:** `tenure`, `ChargesMonthly`, `ChargesTotal`, `cuentas_diarias`, `SeniorCitizen`.
   - **CategÃ³ricas:** `gender`, `Partner`, `Dependents`, `PhoneService`, `MultipleLines`, `InternetService`, `OnlineSecurity`, `OnlineBackup`, `DeviceProtection`, `TechSupport`, `StreamingTV`, `StreamingMovies`, `Contract`, `PaperlessBilling`, `PaymentMethod`.

2. **NormalizaciÃ³n y codificaciÃ³n:**
   - `OneHotEncoder` aplicado a las variables categÃ³ricas.
   - `StandardScaler` o `MinMaxScaler` aplicado a las variables numÃ©ricas.

3. **SeparaciÃ³n de datos:**
   - DivisiÃ³n en conjuntos de entrenamiento y prueba mediante `train_test_split` (estratificado para preservar la proporciÃ³n de churn).

4. **Decisiones de modelizaciÃ³n:**
   - Se exploraron diferentes algoritmos de clasificaciÃ³n (RegresiÃ³n LogÃ­stica, Ãrboles de DecisiÃ³n, Random Forest, Gradient Boosting).
   - En caso de desbalance en la variable objetivo, se aplicaron tÃ©cnicas como **SMOTE** o parÃ¡metros de `class_weight`.
   - Las mÃ©tricas principales consideradas fueron *recall* y *f1-score* para la clase churn, priorizando la capacidad de detectar clientes en riesgo.

---

## â–¶ï¸ Instrucciones de EjecuciÃ³n
1. **Clonar o descargar el repositorio.**

2. **Instalar librerÃ­as necesarias:**
```bash
pip install pandas numpy scikit-learn imbalanced-learn matplotlib seaborn
```

3. **Abrir el notebook principal:**
```bash
jupyter notebook Challenge_TelecomX_Parte2_VF.ipynb
```

4. **Ejecutar las celdas en orden**, siguiendo el flujo de:
   - Carga de datos tratados en CSV.
   - Preprocesamiento de variables.
   - DivisiÃ³n train/test.
   - Entrenamiento de modelos.
   - EvaluaciÃ³n de mÃ©tricas y visualizaciones.
   - InterpretaciÃ³n de resultados y conclusiÃ³n.

---

## ğŸ“ˆ Resultados y MÃ©tricas Alcanzadas
Durante la experimentaciÃ³n se obtuvieron los siguientes resultados aproximados:
- **RegresiÃ³n LogÃ­stica:** Accuracy â‰ˆ 0.80, Recall â‰ˆ 0.68, F1-Score â‰ˆ 0.72
- **Random Forest:** Accuracy â‰ˆ 0.85, Recall â‰ˆ 0.72, F1-Score â‰ˆ 0.76
- **Gradient Boosting:** Accuracy â‰ˆ 0.86, Recall â‰ˆ 0.74, F1-Score â‰ˆ 0.78
---


## ğŸ§  InterpretaciÃ³n e Insights (guÃ­a)
- Revisar importancias del modelo ganador: suelen destacar **tipo de contrato**, **mÃ©todo de pago**, **InternetService**, **tenure**, **cargos mensuales/totales** y servicios como **OnlineSecurity/TechSupport**.
- Contrastar con hallazgos del EDA (Parte 1) para coherencia.
- Documentar variables que **aumentan** o **reducen** el riesgo de churn y por quÃ©.


## ğŸš€ Recomendaciones EstratÃ©gicas (ejemplos)
- **SegmentaciÃ³n** por probabilidad de churn y valor del cliente (priorizar alto riesgo/alto valor).
- **CampaÃ±as de retenciÃ³n** para alto riesgo: descuentos, upgrades, bundles de servicios.
- **Mejora del onboarding** y beneficios por permanencia para clientes de baja antigÃ¼edad.
- **Monitoreo** continuo de variables crÃ­ticas (p. ej., spikes en `chargesMonthly`).


## â— Problemas frecuentes y soluciones
- **Desbalance de clases** â†’ aplicar `SMOTE`, `NearMiss` o `class_weight`.
- **Sobreajuste** â†’ *cross-validation*, regularizaciÃ³n, *early stopping* (si se usa boosting), mÃ¡s datos.
- **Data leakage** â†’ hacer *split* antes del preprocesamiento y usar `Pipeline/ColumnTransformer`.
- **Variabilidad de mÃ©tricas** â†’ fijar `random_state`, aumentar K en CV, usar intervalos de confianza.
